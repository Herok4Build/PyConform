#! /usr/bin/env python
"""
createOutputSpecs 

Creates the Json output specification file.

COPYRIGHT: 2016, University Corporation for Atmospheric Research
LICENSE: See the LICENSE.rst file for details
"""

import argparse, os
import json
import miptableparser 
from dateutil.parser import parse
import datetime

# Map netcdf types to python types
data_types = {'char': 'char', 'byte': 'int8', 'short': 'int16', 'int': 'int32',
              'float': 'float32', 'real': 'float32', 'double': 'float64', 
              'character':'char', 'integer':'int32'}

# The way the date should be formatted in the filenames
date_strings = {'yr': '__YYYY-YYYY__', 'mon': '__YYYYMM-YYYYMM__', 'monClim': '__YYYYMM-YYYYMM-clim__', 
                'day': '__YYYYMMDD-YYYYMMDD__', '6hr': '__YYYYMMDDHHMM-YYYYMMDDHHMM__', 
                '3hr': '__YYYYMMDDHHMM-YYYYMMDDHHMM__', '1hr': '__YYYYMMDDHHMM-YYYYMMDDHHMM__',
                'subhr': '__YYYYMMDDHHMM-YYYYMMDDHHMM__', '1hrClimMon': '__YYYYMMDDHHMM-YYYYMMDDHHMM-clim__'}

def parseArgs(argv = None):

    desc = "This tool creates a specification file that is needed to run PyConform."

    parser = argparse.ArgumentParser(prog='createOutputSpecs',
                                     description=desc)
    parser.add_argument('-d', '--defFile', default=None, type=str,
                        help='A file listing the variable definitions.', required=True)
    parser.add_argument('-g', '--globalAttrFile', default=None, type=str,
                        help='A file listing the global attributes that ' 
                             'are common to all files.')
    parser.add_argument('-e', '--exp', default=None, type=str,
                        help='The name of the experiment.')
    parser.add_argument('-m', '--mipTable', default=None, type=str,
                        help='The name of the MIP table.')
    parser.add_argument('-tt', '--mipTableType', default=None, type=str,
                        help='MIP table file type.  Can be xml, cmor, or excel.')
    parser.add_argument('-u', '--userList', default=None, type=str,
                        help='A file containing cf-compliant names to derive.')
    parser.add_argument('-o', '--outputpath', default=os.getcwd(), type=str,
                        help='Output pathname for the output specification file(s).')

    return parser.parse_args(argv)


def load(defs):

    # Load the definition file - translations from  model variables to requested variables 

    def_dict = {}
    for line in defs:
        line = line.strip()
        # hanle comments
        if '#' in line:
            line = line.split('#')[0].strip()
        # slit definition into the two parts
        split = line.split('=')
        if (len(split) == 2):
            def_dict[split[0].strip()] = split[1].strip()
        else:
            if len(line)>0 :
                print 'Could not parse this line: ',line
    return def_dict

def defineVar(v, varName, attributes, definition, experiment):

    # Get variables needed to piece together the filename
    ripf_list = ['realization_index','initialization_index','physics_index','forcing_index']
    if all (ripf in attributes for ripf in ripf_list):
        ripf = ("r{0}i{1}p{2}f{3}".format(attributes['realization_index'],
                                                     attributes['initialization_index'],
                                                     attributes['physics_index'],
                                                     attributes['forcing_index']))
    else:
        ripf = ''
    mip_era = attributes['mip_era']
    activity_id = attributes['activity_id']
    institution_id = attributes['institution_id']
    source_id = attributes['source_id']
    grid = attributes['grid_label']
    version = attributes['version']
    sub_experiment_id = attributes['sub_experiment_id']
    #today = datetime.datetime.now()
    #version = 'v'+str(today.year).zfill(4)+str(today.month).zfill(2)+str(today.day).zfill(2)

    # modify and add to the global attributes that are requested
    v2 = dict(v)
    for key,value in v.iteritems(): # remove all attributes that do not have values
        if value == '':
            v2.pop(key,None)

    attributes2 = dict(attributes)

    attributes2["variable_id"] = v["variable_id"]
    attributes2["realm"] = v["realm"]
    attributes2["creation_date"]=""
    attributes2.pop('version',None)

    # Put together the filename
    mipTable = v['mipTable']
    if v["frequency"] in date_strings.keys():
        dst = date_strings[v["frequency"]]
    else:
        dst = ''
    f_name = ("{0}/{1}/{2}/{3}/{4}/{5}/{6}/{7}/{8}/{9}/{10}_{11}_{12}_{13}_{14}_{15}{16}.nc".format(
               mip_era, activity_id, institution_id, source_id, experiment, ripf, mipTable,
               varName, grid, version,
               varName, mipTable, experiment, source_id, ripf, grid, dst))

    var = {}
    # handle things that still aren't set correctly in the request
    for k1,v1 in v.iteritems():
        if not isinstance(v1,(list,str,float)):
            v[k1] = "None"

    # create proper url for the further_info_url global attribute
    info_url = "{0}.{1}.{2}.{3}.{4}.{5}".format(mip_era, institution_id, source_id, experiment, sub_experiment_id, ripf) 
    attributes2['further_info_url'] = attributes2['further_info_url'] + info_url

    # put together the dictionary entry for this variable    
    var["attributes"] = v2
    var["definition"] = definition
    var["file"] = {}
    var["file"]["global_attributes"] = attributes2
    var["file"]["filename"] = f_name
    if 'type' in v.keys() and v['type'] != 'None' and v['type'] != '':
        var["datatype"]  = data_types[v['type']]
    else:
        var["datatype"] = 'None'
    if 'requested' in v.keys():
        if v['requested'] != '':
            var['definition'] =  v['requested']
                   
    if 'coordinates' in v.keys():
        var["dimensions"] = v['coordinates'].split('|')

    # return the variable dictionary with all pieces added
    return var

def defineAxes(v, name):

    # define the axes that is used by at least one of the variables in the file

    var = {}
    v2 = dict(v)

    # remove all of the attributes that have no values    
    for key,value in v.iteritems():
        if value == '':
            v2.pop(key,None)

    # put everything into a variable dictionary
    var["attributes"] = v2
    if 'type' in v.keys():
        var["datatype"]  = data_types[v['type']]
    if 'requested' in v.keys():
        if v['requested'] != '':
            try:
                req = [float(val) for val in v['requested'].split()]
            except ValueError:
                req = v['requested'].split()
            if len(req) > 0:
                var['definition'] = req
            #var['definition'] =  v['requested'] 
    var['dimensions'] = [name]

    # return the variable dictionary with all pieces added
    return var


def defineUserVars(fn, var_list, missing_list):

    # create variables from a list supplied by the user

    with open(fn) as f:
        for vr in f:
            vr = vr.strip()
            if vr != "":
                var = {}
                f_id = vr
                if vr in definitions.keys():
                    var["attributes"] = {}
                    var["definition"] = definitions[vr]
                    f_name = ("{0}{1}".format(vr,fn_suffix))
                    var["filename"] = f_name
                    var["datatype"]  = "None"
                    var["dimensions"] = "None"
                    var_list[f_id] = var
                else:
                    missing_list.append(vr)

    return var_list, missing_list


def create_output(exp_dict, definitions, attributes, output_path, args):

    # create the output json files

    TableSpec = {}
    AllMissing = {}

    # go through each one of the data requests from the experiments
    for t,table_dict in exp_dict.iteritems():

        ReqSpec = {}
        variables = {}
        axes = {}
        table_info = {}

        AllMissing[t] = []

        # separate the data request
        variables = table_dict['variables']
        axes = table_dict['axes']
        table_info = table_dict['table_info']
        attributes.update(table_info)
        if 'generic_levels' in table_info.keys():
            g_levels = table_info['generic_levels']
            g_split = g_levels.split(' ')
            for l in g_split:
                axes[l] = {}

        identifier = t
        experiment = args.exp

        var_list = {}
        missing_def_var_list = []

        # Add axes into the variable list
        for v,d in axes.iteritems():
            var_list[v] = defineAxes(d, v)
            if v in definitions.keys() and 'definition' not in var_list[v].keys():
                var_list[v]['definition'] = definitions[v]


        # For each variable in the definition file, create a file entry in the spec and define it
        for v,d in variables.iteritems():
            if v in definitions.keys():
                var_list[v] = defineVar(d, v, attributes, definitions[v], experiment)
                ts_key = var_list[v]["file"]["global_attributes"]["activity_id"]+'_'+var_list[v]["attributes"]["mipTable"]
                if ts_key not in TableSpec.keys():
                    TableSpec[ts_key] = {}
                TableSpec[ts_key][v] = var_list[v]
                for dim in var_list[v]["dimensions"]:
                    if dim not in TableSpec[ts_key].keys() and dim != '':
                        TableSpec[ts_key][dim] = var_list[dim] 
            else:
                missing_def_var_list.append(v)
                AllMissing[t].append(v)

        # Go through a user supplied list if specified
        if args.userList and os.path.isfile(args.userList):
            var_list,missing_def_var_list = defineUserVars(args.userList, var_list, missing_def_var_list)
        else:
            if args.userList and not os.path.isfile(args.userList):
                print 'The User Variable List file does not exist: ',args.userList

        ReqSpec["variables"] = var_list
        ReqSpec["variables_missing_defs"] = sorted(missing_def_var_list)

        # Write the JSON request spec file
        f = output_path + '/' +experiment + '/byRequest/' + experiment + '_' + identifier + '_spec.json'
        if not os.path.exists(output_path+'/' +experiment + '/byRequest/'):
            os.makedirs(output_path + '/' +experiment + '/byRequest/')
        with open(f, 'w') as outfile:
            json.dump(ReqSpec, outfile, sort_keys=True, indent=4)

    # create json files per MIP+table
    for n,t in TableSpec.iteritems():
        spec = {}
        f = output_path + '/' +experiment + '/byTable/' + experiment + '_' + n + '_spec.json'
        if not os.path.exists(output_path+'/' +experiment + '/byTable/'):
            os.makedirs(output_path + '/' +experiment + '/byTable/')
        spec["variables"] = t
        with open(f, 'w') as outfile:
            json.dump(spec, outfile, sort_keys=True, indent=4)

    f = output_path + '/' +experiment + '/byTable/MISSING_DEFS.json'
    with open(f, 'w') as outfile:
        json.dump(AllMissing, outfile, sort_keys=True, indent=4)

def main(argv=None):
   
    args = parseArgs(argv)
    
    print "\n" 
    print "------------------------------------------"
    print 'Running createOutputSpecs with these args:\n'
    print 'Variable Definitions: ', args.defFile
    print 'Global Attributes to be added to each file: ', args.globalAttrFile
    print 'Experiment Name: ', args.exp
    print 'MIP Table to be used: ', args.mipTable
    print 'MIP Table Type: ',args.mipTableType
    print 'User supplied variable list: ',args.userList
    print 'Will create output spec files within this directory:', args.outputpath
    print "------------------------------------------"

    # Open/Read the definition file
    if os.path.isfile(args.defFile):
        with open(args.defFile) as y_definitions:
            definitions = load(y_definitions)
            #print 'DEFINITIONS: ',definitions
    else:
        print 'Definition file does not exist: ',args.defFile
        os.sys.exit(1)

    # Open/Read the global attributes file
    attributes = {}
    if args.globalAttrFile and os.path.isfile(args.globalAttrFile):
        with open(args.globalAttrFile) as y_attributes:
            attributes = load(y_attributes)
            #print 'GLOBAL ATTRIBUTES: ',attributes
    else:
        if args.globalAttrFile and not os.path.isfile(args.globalAttrFile):    
            print 'Global Attributes file does not exist: ',args.globalAttrFile
            os.sys.exit(1)

    # Open/Read the MIP table
#    if args.mipTable != None and args.mipTableType != None and args.exp != None:
    if args.mipTableType != None and args.exp != None:
        exp_dict = miptableparser.mip_table_parser(args.exp, args.mipTable,type=args.mipTableType)

    # Write the spec files out to disk
    create_output(exp_dict, definitions, attributes, args.outputpath, args)

if __name__ == '__main__':
    main()
